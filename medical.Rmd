---
title: "SIM - Assignment 1"
author: "Míriam Méndez, Gabriel Zarate"
date: \today
output: pdf_document
subtitle: "Medical cost"
editor_options: 
  chunk_output_type: console
---

*Loading Libraries*

```{r}
# Load Required Packages: to be increased over the course

requiredPackages <- c("missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","chemometrics","rpart","ROCR","corrr","readxl","RColorBrewer","psych","corrplot","plotly","xlsx","reshape2","scales","stargazer","kableExtra","lmtest","MASS","effects","car")

package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})

```

*Reading Data*

```{r}
df <- read.csv("insurance.csv")
summary(df)

#View(df)
```

# Data Preparation

## Remove duplicates

```{r}
df[duplicated(df), ]
nrow(df)

df <- df[!duplicated(df), ]
nrow(df)
```

## Fixing Structural Errors

```{r}

```

## Check Data Types

The columns sex, smoker and region were casted to factors.

```{r}
lapply(df, class)
categ_cols <- c( 'sex', 'smoker', 'region')
df[categ_cols] = lapply(df[categ_cols], FUN = as.factor)
lapply(df, class)

```

## Univariate Outliers

To detect outliers it was decided to check both mild and severe outliers, as it is shown in the boxlpot, the green line show the mild and the red show the severe outliers. Finally it was decided to cast the severe as NA, to be treaten after.

```{r}
par(mfrow=c(1,2))

Boxplot(df[,c(1,3,4)])
#Age no outliers
#Children no outliers

Boxplot(df$bmi)
Boxplot(df$charges)
#bmi and charges seem to have outliers

#Checking outliers for bmi

ss<-summary(df$bmi);ss
# Upper/lower severe threshold
utso2<-ss[5]+3*(ss[5]-ss[2]);utso2
utsi2<-ss[2]-3*(ss[5]-ss[2]);utsi2
# Upper/lower mild threshold
utmo2<-ss[5]+1.5*(ss[5]-ss[2]);utmo2
utmi2<-ss[2]-1.5*(ss[5]-ss[2]);utmi2

Boxplot(df$bmi,id=list(n=Inf,labels=row.names(df)))
Boxplot(df$bmi)
abline(h=utso2,col="red",lwd=3)
abline(h=utsi2,col="red",lwd=3)
abline(h=utmo2,col="green",lwd=3)
abline(h=utmi2,col="green",lwd=3)

lls.bmi<-which((df$bmi>utso2)|(df$bmi<utsi2));lls.bmi
df[lls.bmi,]
llm.bmi<-which((df$bmi>utmo2)|(df$bmi<utmi2));llm.bmi
df[llm.bmi,]

par(mfrow=c(1,1))

#Checking outliers for charges

ss<-summary(df$charges);ss
# Upper/lower severe threshold
utso2<-ss[5]+3*(ss[5]-ss[2]);utso2
utsi2<-ss[2]-3*(ss[5]-ss[2]);utsi2
# Upper/lower mild threshold
utmo2<-ss[5]+1.5*(ss[5]-ss[2]);utmo2
utmi2<-ss[2]-1.5*(ss[5]-ss[2]);utmi2

Boxplot(df$charges,id=list(n=Inf,labels=row.names(df)))
Boxplot(df$charges)
abline(h=utso2,col="red",lwd=3)
abline(h=utsi2,col="red",lwd=3)
abline(h=utmo2,col="green",lwd=3)
abline(h=utmi2,col="green",lwd=3)

lls<-which((df$charges>utso2)|(df$charges<utsi2));lls
df[lls,]
llm<-which((df$charges>utmo2)|(df$charges<utmi2));llm
df[llm,]

par(mfrow=c(1,1))

#Setting severe outliers from charges as NA

df[lls,"charges"]<-NA

summary(df$charges)
```

## Treating missing data

Checking the missing data, it was seen that the only column with missing data was charges (the oultliers casted before). Those values can't be imputed because it is the target variable, so they were deleted.

```{r}
mis_col = colSums(is.na(df))
mis_col

#Only charges has missing data (outliers)

#They can't be imputed because it is the target variable, so they are deleted

md<-which(is.na(df$charges));md
df <- df[-md,]
nrow(df)

```

## Multivariate Outliers

It was decided to use Mahalanobis distance to detect the multivariate outliers, getting only one, and it was deleted.

```{r}
res.mout <- Moutlier( df[ , c(1,3,4,7)], quantile = 0.999 )

par(mfrow=c(1,1))
plot( res.mout$md, res.mout$rd )
abline( h=res.mout$cutoff, lwd=2, col="red")
abline( v=res.mout$cutoff, lwd=2, col="red")

llmout <- which( ( res.mout$md > res.mout$cutoff ) & (res.mout$rd > res.mout$cutoff) );llmout
df[llmout,]
res.mout$md[llmout]

#Since there is only one multivariate outlier, we delete it
df <- df[-llmout,]

```

## Data Validation

```{r}
summary(df)
```

# Second part

## Create factors for qualitative variables [Done]

```{r}
summary(df)
str(df)
```

## Determine if the response variable (charges) has an acceptably normal distribution

The distribution of charges is right-skewed. We can confirm this visually using a histogram and comparing it with a curve that represents a normal distribution, also the Shapiro Test was applied to check the normality of the distribution, getting a p-value lower that any acceptable alpha, rejecting the H0, so it does not has a normal distribution.

Additionally, the normality of the logarithmic transformation of charge was tested, getting the same results by checking the histogram, comparing it with the curve, and by applying the Shapiro Test, rejecting the H0, so it does not has a log-normal distribution.

```{r}

#Normal Check
hist(df$charges, freq=F, main="charges")
curve(dnorm(x,mean(x),sd(x)),lwd=2,add=T,col="red")
shapiro.test(df$charges)

#Log normal check
hist(log(df$charges), freq=F, main="charges")
curve(dnorm(x,mean(x),sd(x)),lwd=2,add=T,col="red")
shapiro.test(log(df$charges))

```

It does not have an acceptable normal distribution. Most of the individuals spend between \$0 and \$15,000 on health insurance, although the tail of the distribution extends far these peaks.

## Address test to discard serial correlation [Done]

By using the acf() method to plot the autocorrelation in charges, it can be seen that there is no serial correlation in it. Also the Durbin-Watson Test was realized, and it gets a p-value = 0.53, so the H0 fails to be rejected, so it can be said that there is no autocorrelation present in charges.

```{r}

# autocorrelation
acf(df$charges)

# Durbin-Watson Test for serial correlation
dwtest(df$charge ~ 1)

```

The autocorrelation is significantly different from zero at 5% level and we can see that there are periods of low and high variance.

## Detect univariant and multivariant outliers [Done]

Done in the preprocessing

## Preliminary exploratory analysis [Done]

Non of the correlations in the matrix are considered strong, whereas all have a positive correlation, meaning that as *feature 1* increase, *feature 2* also increase.

In these scatter plots we have found interesting relationships between:

-   *age* and *charges* : displays several relatively straight lines.

-   *bmi* and *charges*: has two distinct groups of points.

```{r}
cor(df[c(7,1,3,4)])
pairs.panels(df[c(7,1,3,4)])
plot(df[c(7,1,3,4)])
```

Also checking the condes() function, we can see the following:

-   With the numeric variables: There is small positive correlation with age, an smaller with bmi, and there is almost no correlation with children

-   With the categorical: there is a moderately high coefficient of determination with smoker, so we can say that it is an influential variable

```{r}

res.con <- condes( df, num.var=7, proba = 0.01 )
res.con$quanti
res.con$quali
res.con$category
```

Checking the relation of charges with the other numerical variables by using graphics:

-   With age it can be seen that there seems to be three patterns, but all of them follow a exponential increase, with only the difference that each pattern has a different domain in charges.

-   With bmi it can bee seen that there is no clear pattern, but it can be seen that there are higher charges (\>30000) more frequently in cases where the bmi is higher than 30

-   With children there is no clear pattern, only that there are higher charges for people with less than 3 children than the ones with 4 or 5

```{r}
par( mfrow = c(2,2))
plot(df$charges ~ df$age)
plot(df$charges ~ df$bmi)
plot(df$charges ~ df$children)
par( mfrow = c(1,1))

```

Checking the relation of charges with the other categorical variables by using graphics:

-   With sex seems to not be any significative differences between sex, only that the charges for the 3rd Qu. of male is higher than the female one.

-   With smoker it can be seen that there is a significant difference in charges depending on this variable, if the person smokes it tends to get higher charges. So this variable is going to be impactful to charges.

-   With region eems to not be any significative differences between them

```{r}
par( mfrow = c(2,2))
plot(df$charges ~ df$sex)
tapply(df$charges, df$sex, summary)
plot(df$charges ~ df$smoker)
tapply(df$charges, df$smoker, summary)
plot(df$charges ~ df$region)
tapply(df$charges, df$region, summary)
par( mfrow = c(1,1))
```

Checking the relation of charges with the interaction of other variables:

-   With this plots it can be confirmed that smoker affects every variable, because its combination with any numerical variable affects the charges, because all the higher charges are associated with the people being smokers

-   Sex and region does not have impact in the charges despite combining it with the other numerical variables

-   In the graphic of charges \~ age coloring by smoker it can bee seen that the three patterns previously detected are affected, one pattern (less charges) is only for none smokers, the mid one is a mix of smokers and none smokers, and the higher one is only smokers

```{r}
ggplot(df, aes(x=age , y = charges, color = smoker)) + geom_point()
ggplot(df, aes(x=age , y = charges, color = sex)) + geom_point()
ggplot(df, aes(x=age , y = charges, color = region)) + geom_point()

ggplot(df, aes(x=bmi , y = charges, color = smoker)) + geom_point()
ggplot(df, aes(x=bmi , y = charges, color = sex)) + geom_point()
ggplot(df, aes(x=bmi , y = charges, color = region)) + geom_point()

ggplot(df, aes(x=children , y = charges, color = smoker)) + geom_point()
ggplot(df, aes(x=children , y = charges, color = sex)) + geom_point()
ggplot(df, aes(x=children , y = charges, color = region)) + geom_point()

```

##### Conclusions

-   The variable age has three cuadratic patterns in terms of charges

-   The variable smoke is of high impact to charges, if the people smokes it tends to have higher charges

## Model

First with only the numerical variables

```{r}

#First we try the combinations of age

m0a1 <- lm(charges ~ age, data = df)
summary(m0a1)
plot(df$charges ~ df$age)
lines(df$age, fitted(m0a1), lty = 2,col="red")

m0a2 <- lm(charges ~ age+ I(age^2), data = df)
summary(m0a2)
lines(df$age, fitted(m0a2), lty = 2,col="darkgreen")

m0a3 <- lm(charges ~ I(age^2), data = df)
summary(m0a3)
lines(df$age, fitted(m0a3), lty = 2,col="pink")

AIC(m0a1,m0a2,m0a3, k=log(nrow(df)))

#Seems that using a polinomic aproach in age it would work better

#Now we check with bmi
m0b <- lm(charges ~ bmi, data = df)
summary(m0b)
plot(df$charges ~ df$bmi)
lines(df$bmi, fitted(m0b), lty = 2,col="red")
#there seems to not be a pattern

#Now we check with children
m0c <- lm(charges ~ children, data = df)
summary(m0c)
plot(df$charges ~ df$children)
lines(df$children, fitted(m0c), lty = 2,col="red")
#there seems to not be a pattern
```

```{r}
#Now we try all the numeric values

m0 <- lm(charges ~ age + bmi + children , data = df)
summary(m0)

#The intercept is difficult to interpret because it is impossible to have 0's for all values

par( mfrow = c(2,2))
plot(m0, id.n = 0)
par( mfrow = c(1,1))


#Variance inflation factor
vif(m0)
boxcox( charges ~ age + bmi + children , data=df) #lambda = 0
boxTidwell( charges ~ age + bmi + I(children+0.5) , data=df) #lambda age = 1.8
boxTidwell( log(charges) ~ age + bmi + I(children+0.5) , data=df) #lambda age = 0.5

# First we will try the polinomic convertion with age

m1 <- lm(log(charges) ~ age + I(age^2) + bmi + I(children+0.5) , data = df)
summary(m1) # R2 = 0.3081

m2 <- lm(log(charges) ~  I(age^2) + bmi + I(children+0.5) , data = df)
summary(m2) #R2 = 0.2946

anova(m2,m1) # both models are not equivalent

AIC(m1,m2,  k=log(nrow(df))) #m1 has the best BIC (3079.546)

summary(m1)$r.squared 
#So until now we keep m1, that has R2 =  0.3081237

```

Now we check influential Data

Apriori influent data

```{r}

residualPlots( m1, id=list(n=5, labels=rownames(df)))
marginalModelPlots(m1, id=list(n=5, labels=rownames(df)))

#we use 2 because it is a small dataset
llev <- which( hatvalues(m1) > 2*(length(coef(m1))/nrow(df)));llev
length(llev)

#We try a model without those values only to check, but it won't be kept
m3 <- lm(log(charges) ~  age + I(age^2) + bmi + I(children+0.5) , data = df[-llev,])
summary(m3) # R2 = 0.3047

residualPlots(m3)
marginalModelPlots(m3, id=list(n=5, labels=rownames(df)))

```

Aposteriori influent data

```{r}
# Threshold Chatterjee-Hadi
thChH <- 4/ (nrow(df) - length(coef(m1)));thChH

par(mfrow=c(1,1))
influencePlot(m1)

#Actual influent data Cook´s distance: outliers in cook´s distance
Boxplot(cooks.distance(m1))
abline(h=thChH,col="red",lwd=3)

resout <- which( cooks.distance(m1) > thChH);resout
length(resout)

# We try a model with no Cook's distance outliers
m4 <- lm(log(charges) ~  age + I(age^2) + bmi + I(children+0.5) , data = df[-resout,])
summary(m4) # R2 = 0.5196
residualPlots( m4)
marginalModelPlots(m4, id=list(n=5, labels=rownames(df)))

length(df[,1])
length(df[-resout,1])
```

Residual Outliers

```{r}

```

Adding factors

```{r}
names(df)
m5 <- lm(log(charges) ~  age +I(age^2) + bmi + I(children+0.5) + sex + smoker + region, data = df[-resout,])
summary(m5) #R2 = 0.8293

par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))

Anova(m5)
#all variables are important

plot(allEffects(m5))
m6 <- step( m5,  k=log(nrow(df)))

#Step doesn't show any variable that can be deleted

#But we try a model without region, because it is a multiclass
m5reg <- lm(log(charges) ~  age +I(age^2) + bmi + I(children+0.5) + sex + smoker,  data = df[-resout,])
summary(m5reg)

anova(m5reg, m5)
#Ho rejected, so models are not equivalent, so we can not delete region

```

Redefining factors

```{r}

#First we check how to regroup region
plot(df$charges ~ df$region)
tapply(df$charges, df$region, summary)

#According to the distributions by each group the south seems to have a common distribution by checking the min value, the median and the max, and the same with the north, so we will group them by north and south

df$f.reg<-0
ll<-which(df$region %in% c("northeast","northwest"))
df$f.reg[ll]<-1
df$f.reg <- factor( df$f.reg, labels=c("south","north"))

table(df$region)
table(df$f.reg)


#Also it was decided to check bmi to see if it can become a factor

summary(df$bmi)
summary(df$charges)

plot(df$charges ~ df$bmi)
abline( h=30000, lwd=2, col="red")
abline( v=30, lwd=2, col="red")

#As we can see in the distribution ob charges, the 3rd Qu. IS 16390, so above that we can consider expensive charges, so we decided to draw a line in charges of 30000, almost the double of the 3rd Qu. and it can be seen that approximately in bmi's higher than 30 it starts to be more frequent, so it was finally decided to create a factor that indicates if the individual has a bmi higher or equal than 30 or not

df$f.bmi<-0
ll<-which(df$bmi >= 30)
df$f.bmi[ll]<-1
df$f.bmi <- factor( df$f.bmi, labels=c("<30",">=30"))

```

Recalculate the model

```{r}
m6 <- lm(log(charges) ~  age +I(age^2) + bmi + I(children+0.5) + sex + smoker + f.reg, data = df[-resout,])
summary(m6) # R2 = 0.8282

m7 <- lm(log(charges) ~  age +I(age^2) + f.bmi + I(children+0.5) + sex + smoker + f.reg, data = df[-resout,])
summary(m7) # R2 = 0.8281

AIC(m5,m6,m7, k=log(nrow(df)))

#Comparing the models the m6 has the lower BIC(1093.102), so we decide to keep only the region factor transformation for the model
# m6 R2= 0.8282

m8<- step(m6 , k=log(nrow(df)))
#No changes

residualPlots( m8)
marginalModelPlots(m8, id=list(n=5, labels=rownames(df)))
par(mfrow=c(2,2))
plot(m8)
par(mfrow=c(1,1))

```

Adding interactions

```{r}
m9 <- lm(log(charges) ~  (age +I(age^2) +bmi+ I(children+0.5)) * (sex + smoker + f.reg), data = df[-resout,])
summary(m9) #R2: 0.8647

residualPlots( m9)
marginalModelPlots(m9, id=list(n=5, labels=rownames(df)))
par(mfrow=c(2,2))
plot(m9)
par(mfrow=c(1,1))

plot(allEffects(m9))

m10 <- step(m9, k=log(nrow(df)))
summary(m10) #R2 : 0.8628
#lm(formula = log(charges) ~ age + I(age^2) + bmi + I(children + 0.5) + sex + smoker + f.reg + age:sex + age:smoker + age:f.reg + bmi:smoker + I(children + 0.5):smoker, data = df[-resout, ])

AIC(m10,m9,m7, k=log(nrow(df)))

# BIC: 847.5935
marginalModelPlots(m10)
par(mfrow=c(2,2))
plot(m10)
par(mfrow=c(1,1))

plot(allEffects(m10))
```

Residual Analysis and Validation

```{r}
residualPlots(m10)
influencePlot(m10)
#There are no significant cooks distances

residuals(m10)
boxplot(residuals(m10))
```

Redesign model

```{r}
boxcox(sqrt(charges) ~ age + I(age^2) +bmi+ I(children+0.5) , data=df)

boxcox( 1/sqrt(log(charges)) ~ age + I(age^2) +bmi+ I(children+0.5) , data=df) #lambda = - 0.5

boxTidwell( 1/sqrt(log(charges)) ~ age + I(age^2) +bmi+ I(children+0.5) , data=df)

m11<- lm(log(sqrt(charges)) ~ ( I(1/age) +age + I(age^2) +bmi+ I(bmi\^2)+ log(I(children+0.5))) * (smoker + sex+ f.reg), data = df[-resout,])

summary(m11) marginalModelPlots(m11) par(mfrow=c(2,2)) plot(m11) par(mfrow=c(1,1))

```
