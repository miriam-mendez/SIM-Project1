---
title: "SIM - Assignment 1"
author: "Míriam Méndez, Gabriel Zarate"
date: \today
output: pdf_document
subtitle: "Medical cost"
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","ggmap","ggthemes","knitr","chemometrics","rpart","ROCR","corrr","readxl","RColorBrewer","psych","corrplot","plotly","xlsx","reshape2","scales","stargazer","kableExtra","lmtest","MASS","effects","car")

package.check <- lapply(requiredPackages, FUN = function(x) {
  if (!require(x, character.only = TRUE)) {
    install.packages(x, dependencies = TRUE)
    library(x, character.only = TRUE)
  }
})

```


# Data Preparation
We load the dataset, we view the data and we take a look to the statistical summary to check that there no were structural errors and all the data had been read correctly. 

```{r}
df <- read.csv("insurance.csv")
#View(df)
summary(df)
```

## Removing duplicates

```{r}
df[duplicated(df), ]
nrow(df)

df <- df[!duplicated(df), ]
nrow(df)
```

## Checking Data Types
We check the data types of all the features and we casted sex, smoker and region to factors.

```{r}
sapply(df, class)
categ_cols <- c( 'sex', 'smoker', 'region')
df[categ_cols] = lapply(df[categ_cols], FUN = as.factor)
sapply(df, class)

```

## Univariate Outliers

To detect outliers it was decided to check both mild and severe outliers, as it is shown in the boxlpot, the green line show the mild and the red show the severe outliers. Finally it was decided to cast the severe as NA, to be treaten after.

```{r, echo=TRUE}
par(mfrow=c(1,4))

Boxplot(df$bmi) #bmi  seem to have outliers
Boxplot(df$charges) #charges seem to have outliers
Boxplot(df$children) #Children no outliers
Boxplot(df$age) #Age no outliers


par(mfrow=c(1,2))

#Checking outliers for bmi
ss<-summary(df$bmi);
# Upper/lower severe threshold
utso2<-ss[5]+3*(ss[5]-ss[2]);
utsi2<-ss[2]-3*(ss[5]-ss[2]);
# Upper/lower mild threshold
utmo2<-ss[5]+1.5*(ss[5]-ss[2]); 
utmi2<-ss[2]-1.5*(ss[5]-ss[2]); 

Boxplot(df$bmi, main="Checking outliers for bmi")
abline(h=utso2,col="red",lwd=3)
abline(h=utsi2,col="red",lwd=3)
abline(h=utmo2,col="green",lwd=3)
abline(h=utmi2,col="green",lwd=3)

lls.bmi<-which((df$bmi>utso2)|(df$bmi<utsi2));

llm.bmi<-which((df$bmi>utmo2)|(df$bmi<utmi2));


#Checking outliers for charges

ss<-summary(df$charges);
# Upper/lower severe threshold
utso2<-ss[5]+3*(ss[5]-ss[2])
utsi2<-ss[2]-3*(ss[5]-ss[2])
# Upper/lower mild threshold
utmo2<-ss[5]+1.5*(ss[5]-ss[2])
utmi2<-ss[2]-1.5*(ss[5]-ss[2]);

Boxplot(df$charges, main = "Checking outliers for charges" )
abline(h=utso2,col="red",lwd=3)
abline(h=utsi2,col="red",lwd=3)
abline(h=utmo2,col="green",lwd=3)
abline(h=utmi2,col="green",lwd=3)

lls<-which((df$charges>utso2)|(df$charges<utsi2));

llm<-which((df$charges>utmo2)|(df$charges<utmi2));


#Setting severe outliers from charges as NA

df[lls,"charges"]<-NA

summary(df$charges)
```

## Treating missing data

Checking the missing data, it was seen that the only column with missing data was charges (the oultliers casted before). Those values can't be imputed because it is the target variable, so they were deleted.

```{r}
mis_col = colSums(is.na(df))
mis_col

#Only charges has missing data (outliers)

#They can't be imputed because it is the target variable, so they are deleted

md<-which(is.na(df$charges));md
df <- df[-md,]
nrow(df)

```

## Multivariate Outliers

It was decided to use Mahalanobis distance to detect the multivariate outliers, getting only one, and it was deleted.

```{r}
res.mout <- Moutlier( df[ , c(1,3,4,7)], quantile = 0.999 )

par(mfrow=c(1,1))
plot( res.mout$md, res.mout$rd )
abline( h=res.mout$cutoff, lwd=2, col="red")
abline( v=res.mout$cutoff, lwd=2, col="red")

llmout <- which( ( res.mout$md > res.mout$cutoff ) & (res.mout$rd > res.mout$cutoff) );
res.mout$md[llmout]

#Since there is only one multivariate outlier, we delete it
df <- df[-llmout,]

```

## Data Validation
All the data seems correct,((((REVIEW)))) although we have realized that the bmi values are very high, we have decided to leave them be since they could be possible ((((())))), thus we haven't need to imputate anything.

```{r, include=FALSE}
summary(df)
```

# Second part

The qualitative variables were casted as factors in preprocessing, therefore we proceed to check the normality of the response variable.

```{r, include = FALSE}
summary(df)
str(df)
```

## Determine if the response variable (charges) has an acceptably normal distribution

The distribution of charges is right-skewed. We can confirm this visually using a histogram and comparing it with a curve that represents a normal distribution, also the Shapiro Test was applied to check the normality of the distribution, getting a p-value lower that any acceptable alpha, rejecting the H0, so it does not has a normal distribution.

Additionally, the normality of the logarithmic transformation of charge was tested, getting the same results by checking the histogram, comparing it with the curve, and by applying the Shapiro Test, rejecting the H0, so it does not has a log-normal distribution.

```{r}
par(mfrow=c(2,2))

#Normal Check
hist(df$charges, freq=F, main="charges")
curve(dnorm(x,mean(x),sd(x)),lwd=2,add=T,col="red")

#Log normal check
hist(log(df$charges), freq=F, main="charges")
curve(dnorm(x,mean(x),sd(x)),lwd=2,add=T,col="red")

shapiro.test(df$charges)
shapiro.test(log(df$charges))

```


## Address test to discard serial correlation [Done]

By using the acf() method to plot the autocorrelation in charges, it can be seen that there is no serial correlation in it. Also the Durbin-Watson Test was realized, and it gets a p-value = 0.53, so the H0 fails to be rejected, so it can be said that there is no autocorrelation present in charges.

```{r}

# autocorrelation
acf(df$charges)

# Durbin-Watson Test for serial correlation
dwtest(df$charge ~ 1)

```

## Detect univariant and multivariant outliers [Done]

Done in the preprocessing

## Preliminary exploratory analysis [Done]

First of all, we studied the correlations and non of them were considered strong, nevertheless all had a positive correlation, meaning that as *feature 1* increase, *feature 2* also increase.

Secondly, in these scatter plots we found interesting relationships between:

-   *age* and *charges* : displays several relatively straight lines.

-   *bmi* and *charges*: has two distinct groups of points.

```{r}
cor(df[c(7,1,3,4)])
pairs.panels(df[c(7,1,3,4)])
```

Also checking the condes() function, we can see the following:

-   With the numeric variables: There is small positive correlation with age, an smaller with bmi, and there is almost no correlation with children

-   With the categorical: there is a moderately high coefficient of determination with smoker, so we can say that it is an influential variable

```{r}

res.con <- condes( df, num.var=7, proba = 0.01 )
res.con$quanti
res.con$quali
res.con$category
```

Checking the relation of charges with the other numerical variables by using graphics:

-   With age it can be seen that there seems to be three patterns, but all of them follow a exponential increase, with only the difference that each pattern has a different domain in charges.

-   With bmi it can bee seen that there is no clear pattern, but it can be seen that there are higher charges (\>30000) more frequently in cases where the bmi is higher than 30

-   With children there is no clear pattern, only that there are higher charges for people with less than 3 children than the ones with 4 or 5

```{r}
par( mfrow = c(2,2))
plot(df$charges ~ df$age)
plot(df$charges ~ df$bmi)
plot(df$charges ~ df$children)
par( mfrow = c(1,1))

```

Checking the relation of charges with the other categorical variables by using graphics:

-   With sex seems to not be any significative differences between sex, only that the charges for the 3rd Qu. of male is higher than the female one.

-   With smoker it can be seen that there is a significant difference in charges depending on this variable, if the person smokes it tends to get higher charges. So this variable is going to be impactful to charges.

-   With region eems to not be any significative differences between them

```{r}
par( mfrow = c(2,2))
plot(df$charges ~ df$sex)
tapply(df$charges, df$sex, summary)
plot(df$charges ~ df$smoker)
tapply(df$charges, df$smoker, summary)
plot(df$charges ~ df$region)
tapply(df$charges, df$region, summary)
par( mfrow = c(1,1))
```

Checking the relation of charges with the interaction of other variables:

-   With this plots it can be confirmed that smoker affects every variable, because its combination with any numerical variable affects the charges, because all the higher charges are associated with the people being smokers

-   Sex and region does not have impact in the charges despite combining it with the other numerical variables

-   In the graphic of charges \~ age coloring by smoker it can bee seen that the three patterns previously detected are affected, one pattern (less charges) is only for none smokers, the mid one is a mix of smokers and none smokers, and the higher one is only smokers

```{r}
require(gridExtra)
plot1 <- ggplot(df, aes(x=age , y = charges, color = smoker)) + geom_point()
plot2 <- ggplot(df, aes(x=age , y = charges, color = sex)) + geom_point()
plot3 <- ggplot(df, aes(x=age , y = charges, color = region)) + geom_point()
grid.arrange( plot1, plot2,plot3 , ncol=2)

plot1 <-ggplot(df, aes(x=age , y = charges, color = smoker)) + geom_point()
plot2 <-ggplot(df, aes(x=age , y = charges, color = sex)) + geom_point()
plot3 <-ggplot(df, aes(x=age , y = charges, color = region)) + geom_point()
grid.arrange( plot1, plot2,plot3 , ncol=2)

plot1 <-ggplot(df, aes(x=bmi , y = charges, color = smoker)) + geom_point()
plot2 <-ggplot(df, aes(x=bmi , y = charges, color = sex)) + geom_point()
plot3 <-ggplot(df, aes(x=bmi , y = charges, color = region)) + geom_point()
grid.arrange( plot1, plot2,plot3 , ncol=2)

plot1 <-ggplot(df, aes(x=children , y = charges, color = smoker)) + geom_point()
plot2 <-ggplot(df, aes(x=children , y = charges, color = sex)) + geom_point()
plot3 <-ggplot(df, aes(x=children , y = charges, color = region)) + geom_point()
grid.arrange( plot1, plot2,plot3 , ncol=2)

```

##### Conclusions

-   The variable age has three cuadratic patterns in terms of charges

-   The variable smoke is of high impact to charges, if the people smokes it tends to have higher charges

## Model

First with only the numerical variables

```{r}


m0a1 <- lm(charges ~ age, data = df)
summary(m0a1)
plot(df$charges ~ df$age)
lines(df$age, fitted(m0a1), lty = 2,col="red")

m0a2 <- lm(charges ~ age+ I(age^2), data = df)
summary(m0a2)
lines(df$age, fitted(m0a2), lty = 2,col="darkgreen")

m0a3 <- lm(charges ~ I(age^2), data = df)
summary(m0a3)
lines(df$age, fitted(m0a3), lty = 2,col="pink")

AIC(m0a1,m0a2,m0a3, k=log(nrow(df)))

#Seems that using a polinomic aproach in age it would work better

#Now we check with bmi
m0b <- lm(charges ~ bmi, data = df)
summary(m0b)
plot(df$charges ~ df$bmi)
lines(df$bmi, fitted(m0b), lty = 2,col="red")
#there seems to not be a pattern

#Now we check with children
m0c <- lm(charges ~ children, data = df)
summary(m0c)
plot(df$charges ~ df$children)
lines(df$children, fitted(m0c), lty = 2,col="red")
#there seems to not be a pattern
```

```{r}
#Now we try all the numeric values

m0 <- lm(charges ~ age + bmi + children , data = df)
summary(m0)

#The intercept is difficult to interpret because it is impossible to have 0's for all values

par( mfrow = c(2,2))
plot(m0, id.n = 0)
par( mfrow = c(1,1))


#Variance inflation factor
vif(m0)
boxcox( charges ~ age + bmi + children , data=df) #lambda = 0
boxTidwell( charges ~ age + bmi + I(children+0.5) , data=df) #lambda age = 1.8
boxTidwell( log(charges) ~ age + bmi + I(children+0.5) , data=df) #lambda age = 0.5

# First we will try the polinomic convertion with age

m1 <- lm(log(charges) ~ age + I(age^2) + bmi + I(children+0.5) , data = df)
summary(m1) # R2 = 0.3081

m2 <- lm(log(charges) ~  I(age^2) + bmi + I(children+0.5) , data = df)
summary(m2) #R2 = 0.2946

m3 <- lm(log(charges) ~  sqrt(age) + bmi + I(children+0.5) , data = df)
summary(m3) #R2 = 0.3085

anova(m2,m1) # models are not equivalent

AIC(m3,m2,m1, k=log(nrow(df))) #m3 has the best AIC (3045.722)

summary(m3)$r.squared 
#So until now we keep m3, that has R2 =  0.30847

```

Now we check influential Data

Apriori influent data

```{r}

residualPlots( m1, id=list(n=5, labels=rownames(df)))
marginalModelPlots(m1, id=list(n=5, labels=rownames(df)))

#we use 2 because it is a small dataset
llev <- which( hatvalues(m1) > 2*(length(coef(m1))/nrow(df)));llev
length(llev)

#We try a model without those values only to check, but it won't be kept
m3 <- lm(log(charges) ~  sqrt(age) + bmi + I(children+0.5) , data = df[-llev,])
summary(m3) # R2 = 0.3051

residualPlots(m3)
marginalModelPlots(m3, id=list(n=5, labels=rownames(df)))

```

Aposteriori influent data

```{r}
# Threshold Chatterjee-Hadi
thChH <- 4/ (nrow(df) - length(coef(m1)));thChH

par(mfrow=c(1,1))
influencePlot(m1)

#Actual influent data Cook´s distance: outliers in cook´s distance
Boxplot(cooks.distance(m1))
abline(h=thChH,col="red",lwd=3)

resout <- which( cooks.distance(m1) > thChH);resout
length(resout)

# We try a model with no Cook's distance outliers
m4 <- lm(log(charges) ~  sqrt(age) + bmi + I(children+0.5) , data = df[-resout,])
summary(m4) # R2 = 0.513
residualPlots( m4)
marginalModelPlots(m4, id=list(n=5, labels=rownames(df)))

length(df[,1])
length(df[-resout,1])
```

Residual Outliers

```{r}

```

Adding factors

```{r}
names(df)
m6 <- lm(log(charges) ~  sqrt(age) + bmi + I(children+0.5) + sex + smoker + region, data = df[-resout,])
summary(m6) #R2 = 0.8275

par(mfrow=c(2,2))
plot(m6)
par(mfrow=c(1,1))

Anova(m6)
#all variables are important

m7 <- step( m6, k=log(nrow(df)))
#Step doesn't show any variable that can be deleted

#But we try a model without region, because it is a multiclass
m6reg <- lm(log(charges) ~   sqrt(age) + bmi + I(children+0.5) + sex + smoker,  data = df[-resout,])
summary(m6reg) 

anova(m6reg, m6)
#Ho rejected, so models are not equivalent, so we can not delete region

```

Redefining factors

```{r}

#First we check how to regroup region
plot(df$charges ~ df$region)
tapply(df$charges, df$region, summary)

#According to the distributions by each group the south seems to have a common distribution by checking the min value, the median and the max, and the same with the north, so we will group them by north and south

df$f.reg<-0
ll<-which(df$region %in% c("northeast","northwest"))
df$f.reg[ll]<-1
df$f.reg <- factor( df$f.reg, labels=c("south","north"))

table(df$region)
table(df$f.reg)


#Also it was decided to check bmi to see if it can become a factor

summary(df$bmi)
summary(df$charges)

plot(df$charges ~ df$bmi)
abline( h=30000, lwd=2, col="red")
abline( v=30, lwd=2, col="red")

#As we can see in the distribution ob charges, the 3rd Qu. IS 16390, so above that we can consider expensive charges, so we decided to draw a line in charges of 30000, almost the double of the 3rd Qu. and it can be seen that approximately in bmi's higher than 30 it starts to be more frequent, so it was finally decided to create a factor that indicates if the individual has a bmi higher or equal than 30 or not

df$f.bmi<-0
ll<-which(df$bmi >= 30)
df$f.bmi[ll]<-1
df$f.bmi <- factor( df$f.bmi, labels=c("<30",">=30"))

```

Recalculate the model

```{r}

#Checking the change only in region
m8 <- lm(log(charges) ~  sqrt(age) + bmi + I(children+0.5) + sex + smoker + f.reg, data = df[-resout,])
summary(m8) #R2 = 0.8264

#Checking the change in region and in bmi
m9 <- lm(log(charges) ~  sqrt(age) + f.bmi + I(children+0.5) + sex + smoker + f.reg, data = df[-resout,])
summary(m9) #R2 = 0.8261

AIC(m9,m8,m7, k=log(nrow(df)))

#Comparing the models the m8 has the lower BIC(1099.018), so we decide to keep only the region factor transformation for the model

m10<- step(m9, k=log(nrow(df)))
#No changes

residualPlots( m9)
marginalModelPlots(m9, id=list(n=5, labels=rownames(df)))
par(mfrow=c(2,2))
plot(m9)
par(mfrow=c(1,1))

```

Adding interactions

```{r}
m11 <- lm(log(charges) ~  (sqrt(age) +bmi+ I(children+0.5)) * (sex + smoker + f.reg), data = df[-resout,])
summary(m11) #R2 = 0.8643

residualPlots( m11)
marginalModelPlots(m11, id=list(n=5, labels=rownames(df)))
par(mfrow=c(2,2))
plot(m11)
par(mfrow=c(1,1))

plot(allEffects(m11))

m12 <- step(m11, k=log(nrow(df)))
summary(m12) # R2 = 0.8632

#lm(formula = log(charges) ~ sqrt(age) + bmi + I(children + 0.5) + sex + smoker + f.reg + sqrt(age):sex + sqrt(age):smoker + sqrt(age):f.reg + bmi:smoker + data = df[-resout, ])

AIC(m12,m11, k=log(nrow(df)))

marginalModelPlots(m12)
par(mfrow=c(2,2))
plot(m12)
par(mfrow=c(1,1))

plot(allEffects(m12))

```

Residual Analysis and Validation

```{r}
residualPlots(m12)
influencePlot(m12)
#There are no significant cooks distances

```
